{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOLDEN_DATA = [\n",
    "    [\"We price the swap at 54 bips\", {\"We price\": \"RFQ\", \"swap\":\"FIN_PRODUCT\", \"54 bips\":\"CARDINAL\"}, 'FINANCIAL'],\n",
    "    [\"TD offers 1.123 on 10 million of CADUSD\", {\"TD offers\": \"RFQ\", \"CADUSD\":\"CURRENCY_PAIR\", \"1.123\":\"CARDINAL\", '10 million':\"CARDINAL\"}, 'FINANCIAL'],\n",
    "    [\"Names like AMZN trade frequently but tech like TWLO trades on lower volume\", {'TWLO':\"EQUITY_SYMBOL\", 'AMZN':'EQUITY_SYMBOL'}, 'FINANCIAL'],\n",
    "    [\"TD bids 99.91 on US 10s. Done. Thanks for the trade. Confirm to follow\", {'TD bids':\"RFQ\", 'Done.':'TRADE_EXECUTION', 'Thanks for the trade':'TRADE_EXECUTION', 'Confirm to follow':'TRADE_EXECUTION'}, 'FINANCIAL'],\n",
    "    [\"Amazon (AMZN) is trading 13% higher than 12 months ago but 22% lower than the peak\", {'AMZN':\"EQUITY_SYMBOL\"}, 'FINANCIAL'],\n",
    "    [\"The river Amazon flows mostly through Brazil\", {}, 'NON-FINANCIAL']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We price the swap at 54 bips</td>\n",
       "      <td>FINANCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TD offers 1.123 on 10 million of CADUSD</td>\n",
       "      <td>FINANCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Names like AMZN trade frequently but tech like...</td>\n",
       "      <td>FINANCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TD bids 99.91 on US 10s. Done. Thanks for the ...</td>\n",
       "      <td>FINANCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon (AMZN) is trading 13% higher than 12 mo...</td>\n",
       "      <td>FINANCIAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Classification\n",
       "0                       We price the swap at 54 bips      FINANCIAL\n",
       "1            TD offers 1.123 on 10 million of CADUSD      FINANCIAL\n",
       "2  Names like AMZN trade frequently but tech like...      FINANCIAL\n",
       "3  TD bids 99.91 on US 10s. Done. Thanks for the ...      FINANCIAL\n",
       "4  Amazon (AMZN) is trading 13% higher than 12 mo...      FINANCIAL"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=GOLDEN_DATA, columns=['Text', 'dropme', 'Classification']).drop('dropme', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Classification'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample: The river Amazon flows mostly through Brazil\n",
      "Classification: NON-FINANCIAL\n",
      "Training Data Shape: (4, 2)\n",
      "Testing Data Shape: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Test sample:', train['Text'].iloc[0])\n",
    "print('Classification:', train['Classification'].iloc[0])\n",
    "print('Training Data Shape:', train.shape)\n",
    "print('Testing Data Shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "sns.barplot(x = train['Classification'].unique(), y=train['Classification'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Define function to cleanup text by removing personal pronouns, stopwords, and puncuation\n",
    "def cleanup_text(docs, logging=False):\n",
    "    texts = []\n",
    "    counter = 1\n",
    "    for doc in docs:\n",
    "        if counter % 1000 == 0 and logging:\n",
    "            print(\"Processed %d out of %d documents.\" % (counter, len(docs)))\n",
    "        counter += 1\n",
    "        doc = nlp(doc, disable=['parser', 'ner'])\n",
    "        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "        tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
    "        tokens = ' '.join(tokens)\n",
    "        texts.append(tokens)\n",
    "    return pd.Series(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We price the swap at 54 bips</td>\n",
       "      <td>FINANCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TD offers 1.123 on 10 million of CADUSD</td>\n",
       "      <td>FINANCIAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Classification\n",
       "0             We price the swap at 54 bips      FINANCIAL\n",
       "1  TD offers 1.123 on 10 million of CADUSD      FINANCIAL"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "# spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanTextTransformer(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        a = [cleanText(text) for text in X]\n",
    "#         print(a)\n",
    "        return a\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "def cleanText(text):\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tokenizeText(sample):\n",
    "    tokens = parser(sample)\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "#     print(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 best: \n",
      "Class 2 best: \n",
      "0 The river Amazon flows mostly through Brazil NON-FINANCIAL\n",
      "[ 9 11  6 19]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "def printNMostInformative(vectorizer, clf, N):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    topClass1 = coefs_with_fns[:N]\n",
    "    topClass2 = coefs_with_fns[:-(N + 1):-1]\n",
    "    print(\"Class 1 best: \")\n",
    "    for feat in topClass1:\n",
    "        pass #print(feat)\n",
    "    print(\"Class 2 best: \")\n",
    "    for feat in topClass2:\n",
    "        pass #print(feat)\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))\n",
    "clf = LinearSVC()\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)])\n",
    "\n",
    "# data\n",
    "train1 = train['Text'].tolist()\n",
    "labelsTrain1 = train['Classification'].tolist()\n",
    "\n",
    "test1 = test['Text'].tolist()\n",
    "labelsTest1 = test['Classification'].tolist()\n",
    "# train\n",
    "pipe.fit(train1, labelsTrain1)\n",
    "\n",
    "# test\n",
    "preds = pipe.predict(test1)\n",
    "# print(\"accuracy:\", accuracy_score(labelsTest1, preds))\n",
    "# print(\"Top 10 features used to predict: \")\n",
    "\n",
    "printNMostInformative(vectorizer, clf, 10)\n",
    "\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer)])\n",
    "transform = pipe.fit_transform(train1, labelsTrain1)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(len(train1)):\n",
    "    print(i, train1[i], labelsTrain1[i])\n",
    "    s = \"\"\n",
    "    indexIntoVocab = transform.indices[transform.indptr[i]:transform.indptr[i+1]]\n",
    "    print(indexIntoVocab)\n",
    "    numOccurences = transform.data[transform.indptr[i]:transform.indptr[i+1]]\n",
    "    print(numOccurences)\n",
    "    for idx, num in zip(indexIntoVocab, numOccurences):\n",
    "        s += str((vocab[idx], num))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-8dd7a5abd9db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict not found"
     ]
    }
   ],
   "source": [
    "preds = transform.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Names like AMZN trade frequently but tech like TWLO trades on lower volume'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab[1913], vocab[1347], vocab[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    FINANCIAL       1.00      0.50      0.67         2\n",
      "NON-FINANCIAL       0.00      0.00      0.00         0\n",
      "\n",
      "    micro avg       0.50      0.50      0.50         2\n",
      "    macro avg       0.50      0.25      0.33         2\n",
      " weighted avg       1.00      0.50      0.67         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(labelsTest1, preds, \n",
    "                                    target_names=df['Classification'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "*****\n",
      "['NON-FINANCIAL']\n",
      "Top 10 features used to predict: \n",
      "Class 1 best: \n",
      "(-0.253799363849912, 'trade')\n",
      "(-0.1207442621539155, 'amzn')\n",
      "(-0.1207442621539155, 'low')\n",
      "(-0.10164198107206239, '10s')\n",
      "(-0.10164198107206239, '99.91')\n",
      "(-0.10164198107206239, 'bid')\n",
      "(-0.10164198107206239, 'confirm')\n",
      "(-0.10164198107206239, 'follow')\n",
      "(-0.10164198107206239, 'td')\n",
      "(-0.10164198107206239, 'thank')\n",
      "Class 2 best: \n",
      "(0.23849441719428124, 'river')\n",
      "(0.23849441719428124, 'flow')\n",
      "(0.23849441719428124, 'brazil')\n",
      "(0.14916327566429988, 'amazon')\n",
      "(-0.03141312062393412, 'volume')\n",
      "(-0.03141312062393412, 'twlo')\n",
      "(-0.03141312062393412, 'tech')\n",
      "(-0.03141312062393412, 'frequently')\n",
      "(-0.06282624124786824, 'like')\n",
      "(-0.08933114152998138, 'peak')\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))\n",
    "clf = LinearSVC()\n",
    "\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)])\n",
    "# data\n",
    "train1 = train['Text'].tolist()\n",
    "labelsTrain1 = train['Classification'].tolist()\n",
    "test1 = test['Text'].tolist()\n",
    "labelsTest1 = test['Classification'].tolist()\n",
    "# train\n",
    "pipe.fit(train1, labelsTrain1)\n",
    "# test\n",
    "preds = pipe.predict(test1)\n",
    "\n",
    "\n",
    "preds = pipe.predict([\"amazon\"])\n",
    "print(\"*****\")\n",
    "# print(test1)\n",
    "print(\"*****\")\n",
    "print(preds)\n",
    "\n",
    "# print(\"accuracy:\", accuracy_score(labelsTest1, preds))\n",
    "print(\"Top 10 features used to predict: \")\n",
    "\n",
    "printNMostInformative(vectorizer, clf, 10)\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer)])\n",
    "transform = pipe.fit_transform(train1, labelsTrain1)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "for i in range(len(train1)):\n",
    "    s = \"\"\n",
    "    indexIntoVocab = transform.indices[transform.indptr[i]:transform.indptr[i+1]]\n",
    "    numOccurences = transform.data[transform.indptr[i]:transform.indptr[i+1]]\n",
    "    for idx, num in zip(indexIntoVocab, numOccurences):\n",
    "        s += str((vocab[idx], num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
